# -*- coding: utf-8 -*-
"""Hand.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WWTJ0B9akPRZw5TIdDeMYBzzKJ-BOTID

# Image Classification of an American Sign Language Dataset
"""

from google.colab import drive
drive.mount('/content/drive')

import os

os.getcwd()

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Deep

!unzip archive.zip

"""### Reading in the Data"""

import pandas as pd

train_df = pd.read_csv("/content/drive/MyDrive/Deep/sign_mnist_train/sign_mnist_train.csv")
valid_df = pd.read_csv("/content/drive/MyDrive/Deep/sign_mnist_test/sign_mnist_test.csv")

"""### Exploring the Data"""

train_df.head()

"""### Extracting the Labels"""

y_train = train_df['label']
y_valid = valid_df['label']
del train_df['label']
del valid_df['label']

type(y_train)

"""### Extracting the Images"""

x_train = train_df.values
x_valid = valid_df.values

x_train

"""### Summarizing the Training and Validation Data"""

x_train.shape

y_train.shape

y_train

"""For validation, we have 7,172 images..."""

x_valid.shape

y_valid.shape

"""## Visualizing the Data"""

import matplotlib.pyplot as plt
plt.figure(figsize=(40,40))

num_images = 20
for i in range(num_images):
    row = x_train[i]
    label = y_train[i]
    
    image = row.reshape(28,28)
    plt.subplot(1, num_images, i+1)
    plt.title(label, fontdict={'fontsize': 30})
    plt.axis('off')
    plt.imshow(image, cmap='gray')

x_train.min()

x_train.max()

x_train = x_train / 255
x_valid = x_valid / 255

import tensorflow.keras as keras
num_classes = 25

# TODO: Categorically encode y_train and y_valid.

y_train = keras.utils.to_categorical(y_train, num_classes)
y_valid = keras.utils.to_categorical(y_valid, num_classes)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# TODO: build a model following the guidelines above.

model = Sequential()
model.add(Dense(units = 512, activation='relu', input_shape=(784,)))
model.add(Dense(units = 512, activation='relu'))
model.add(Dense(units = num_classes, activation='softmax'))

"""## Summarizing the Model"""

model.summary()

"""## Compiling the Model"""

model.compile(loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(x_train, y_train, epochs=20, verbose=1, validation_data=(x_valid, y_valid))

model.save('handsign.model')

import numpy as np
import string
alphabet = list(string.ascii_lowercase)
img1=x_valid[1]
img=img1
img=np.expand_dims(img,axis=0)
prediction=model.predict(img)
img1=img1.reshape(28,28)
print(f'the handsign letter is {alphabet[np.argmax(prediction)]}')
plt.imshow(img1, cmap='gray')

print(prediction)

"""### Clear the Memory
Before moving on, please execute the following cell to clear up the GPU memory. This is required to move on to the next notebook.
"""

import IPython
app = IPython.Application.instance()
app.kernel.do_shutdown(True)